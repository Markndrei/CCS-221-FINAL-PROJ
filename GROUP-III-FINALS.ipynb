{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['ID', 'NO LABEL', 'PHONE', 'MOUSE']\n",
    "\n",
    "#Creating Realtime Dataset\n",
    "\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height = 800\n",
    "\n",
    "raw_frames_type_1 = []\n",
    "raw_frames_type_2 = []\n",
    "raw_frames_type_3 = []\n",
    "raw_frames_type_4 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while CAMERA.isOpened():\n",
    "    #Read a new camera frame\n",
    "    \n",
    "    ret, frame = CAMERA.read()\n",
    "    \n",
    "    #Flip\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    #Rescale the images output\n",
    "    \n",
    "    aspect = frame.shape[1] / float(frame.shape[0])\n",
    "    res = int(aspect * camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "    \n",
    "    #The green rectangle\n",
    "    cv2.rectangle(frame, (300, 150), (648, 398), (0, 255, 0), 2)\n",
    "    # cv2.rectangle(frame, (300, 75), (650, 425), (0,255,0), 2)\n",
    "    \n",
    "    #Show the frame\n",
    "    cv2.imshow(\"Capturing\", frame)\n",
    "    \n",
    "    #Controls q = quit/ s = capturing\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key & 0xff == ord('q'):\n",
    "        break\n",
    "    elif key & 0xFF == ord('1'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_1.append(frame)\n",
    "    elif key & 0xFF == ord('2'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_2.append(frame)\n",
    "    elif key & 0xFF == ord('3'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_3.append(frame)\n",
    "    elif key & 0xFF == ord('4'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_4.append(frame)\n",
    "        \n",
    "    #preview\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "\n",
    "#Camera\n",
    "CAMERA.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_width = 339\n",
    "save_height = 600\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory %s\" % retval)\n",
    "\n",
    "print('ID: ', len(raw_frames_type_1))\n",
    "print('NO LABEL: ', len(raw_frames_type_2))\n",
    "print('PHONE: ', len(raw_frames_type_3))\n",
    "print('MOUSE: ', len(raw_frames_type_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Crop the images\n",
    "\n",
    "for i, frame in enumerate(raw_frames_type_1):\n",
    "    \n",
    "    #Get roi\n",
    "    # roi = frame[75+2:245-2, 300+2:650-2]\n",
    "    roi = frame[152:398, 302:648]\n",
    "    \n",
    "    #Parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resize to 224x224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    \n",
    "    #save\n",
    "    cv2.imwrite('ID/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, frame in enumerate(raw_frames_type_2):\n",
    "    \n",
    "    #Get roi\n",
    "    roi = frame[152:398, 302:648]\n",
    "    \n",
    "    #Parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resize to 224x224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    \n",
    "    #save\n",
    "    cv2.imwrite('NO LABEL/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frame in enumerate(raw_frames_type_3):\n",
    "    \n",
    "    #Get roi\n",
    "    roi = frame[152:398, 302:648]\n",
    "    \n",
    "    #Parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resize to 224x224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    \n",
    "    #save\n",
    "    cv2.imwrite('PHONE/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "for i, frame in enumerate(raw_frames_type_4):\n",
    "    \n",
    "    #Get roi\n",
    "    roi = frame[152:398, 302:648]\n",
    "    \n",
    "    #Parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Resize to 224x224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    \n",
    "    #save\n",
    "    cv2.imwrite('MOUSE/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from keras import preprocessing\n",
    "from PIL import Image\n",
    "width = 96\n",
    "height = 96\n",
    "\n",
    "images_type_1 = []\n",
    "images_type_2 = []\n",
    "images_type_3 = []\n",
    "images_type_4 = []\n",
    "\n",
    "import keras.api._v2.keras as keras\n",
    "from keras.utils import load_img, img_to_array, array_to_img \n",
    "\n",
    "for image_path in glob('ID/*.*'):\n",
    "    img = Image.open(image_path).resize((width, height))\n",
    "    x = img_to_array(img)\n",
    "    images_type_1.append(x)\n",
    "    \n",
    "for image_path in glob('NO LABEL/*.*'):\n",
    "    img = Image.open(image_path).resize((width, height))\n",
    "    x = img_to_array(img)\n",
    "    images_type_2.append(x)\n",
    "    \n",
    "for image_path in glob('PHONE/*.*'):\n",
    "    img = Image.open(image_path).resize((width, height))\n",
    "    x = img_to_array(img)\n",
    "    images_type_3.append(x)\n",
    "    \n",
    "for image_path in glob('MOUSE/*.*'):\n",
    "    img = Image.open(image_path).resize((width, height))\n",
    "    x = img_to_array(img)\n",
    "    images_type_4.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i,x in enumerate(images_type_1[:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    image = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i,x in enumerate(images_type_2[:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    image = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[1]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i,x in enumerate(images_type_3[:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    image = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[2]))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i,x in enumerate(images_type_4[:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    image = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[3]))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This is where part 1 ends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Image to tensor\n",
    "\n",
    "X_type_1 = np.array(images_type_1)\n",
    "X_type_2 = np.array(images_type_2)\n",
    "X_type_3 = np.array(images_type_3)\n",
    "X_type_4 = np.array(images_type_4)\n",
    "\n",
    "#Check the shape using .shape() check the images count\n",
    "\n",
    "print(X_type_1.shape)\n",
    "print(X_type_2.shape)\n",
    "print(X_type_3.shape)\n",
    "print(X_type_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_type_1, X_type_2), axis = 0)\n",
    "\n",
    "if len(X_type_3):\n",
    "    X = np.concatenate((X, X_type_3), axis = 0)\n",
    "    \n",
    "if len(X_type_4):\n",
    "    X = np.concatenate((X, X_type_4), axis = 0)\n",
    "    \n",
    "#Scaling the data to 1 - 0\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_type_1 = [0 for item in enumerate(X_type_1)]\n",
    "y_type_2 = [1 for item in enumerate(X_type_2)]\n",
    "y_type_3 = [2 for item in enumerate(X_type_3)]\n",
    "y_type_4 = [3 for item in enumerate(X_type_4)]\n",
    "\n",
    "y = np.concatenate((y_type_1, y_type_2), axis = 0)\n",
    "\n",
    "if len(y_type_3):\n",
    "    y = np.concatenate((y, y_type_3), axis = 0)\n",
    "    \n",
    "if len(y_type_4):\n",
    "    y = np.concatenate((y, y_type_4), axis = 0)\n",
    "    \n",
    "y = to_categorical(y, num_classes=len(class_names))\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Config\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default Parameters\n",
    "\n",
    "#Situational Values, you may not adjust these\n",
    "\n",
    "conv_1 = 16\n",
    "conv_1_drop = 0.2\n",
    "conv_2 = 32\n",
    "conv_2_drop = 0.2\n",
    "dense_1_n = 1024\n",
    "dense_1_drop = 0.2\n",
    "dense_2_n = 512\n",
    "dense_2_drop = 0.2\n",
    "\n",
    "#values you can adjust\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_1_drop = conv_1_drop, conv_2_drop = conv_2_drop,\n",
    "                dense_1_n = dense_1_n, dense_1_drop = dense_1_drop,\n",
    "                dense_2_n = dense_2_n, dense_2_drop = dense_2_drop,\n",
    "                lr=lr):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(conv_1, (3,3),\n",
    "                            input_shape = (width, height, color_channels),\n",
    "                            activation = 'relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(conv_1_drop))\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model.add(Convolution2D(conv_2, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(conv_1_drop))\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model.add(Dense(dense_1_n, activation='relu'))\n",
    "    model.add(Dropout(dense_1_drop))\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model.add(Dense(dense_2_n, activation='relu'))\n",
    "    model.add(Dropout(dense_2_drop))\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    model.add(Dense(len(class_names), activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(clipvalue=0.5),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameter\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run yet\n",
    "\n",
    "history = model.fit(X,y, validation_split=0.10, epochs=10, batch_size=30)\n",
    "\n",
    "print(history)\n",
    "\n",
    "#part 2 ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 starts here\n",
    "\n",
    "#Model evaluation\n",
    "\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss and accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plt_show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "id = 'ID/10.png'\n",
    "nolabel = 'NO LABEL/10.png'\n",
    "phone = 'PHONE/10.png'\n",
    "mouse = 'MOUSE/10.png'\n",
    "\n",
    "imgs = [id, nolabel, phone, mouse]\n",
    "\n",
    "classes = None\n",
    "predicted_classes = []\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    type_ = Image.open(imgs[i]).resize((width, height))\n",
    "    plt.imshow(type_)\n",
    "    plt.show()\n",
    "    \n",
    "    type_x      = np.expand_dims(np.array(type_), axis = 0)\n",
    "    prediction  = model.predict(type_x)\n",
    "    index       = np.argmax(prediction)\n",
    "    print(class_names[index])\n",
    "    classes     = class_names[index]\n",
    "    predicted_classes.append(class_names[index])\n",
    "    \n",
    "cm = confusion_matrix(class_names, predicted_classes)\n",
    "f = sns.heatmap(cm, xticklabels=class_names, yticklabels=predicted_classes, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_1 = load_img('ID/10.png', target_size=(width, height))\n",
    "plt.imshow(type_1)\n",
    "plt.show()\n",
    "\n",
    "type_1_x = np.expand_dims(type_1, axis=0)\n",
    "predictions = model.predict(type_1_x)\n",
    "index = np.argmax(predictions)\n",
    "\n",
    "print(class_names[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_2 = load_img('NO LABEL/10.png', target_size=(width, height))\n",
    "plt.imshow(type_2)\n",
    "plt.show()\n",
    "\n",
    "type_2_x = np.expand_dims(type_2, axis=0)\n",
    "predictions = model.predict(type_2_x)\n",
    "index = np.argmax(predictions)\n",
    "\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_3 = load_img('PHONE/10.png', target_size=(width, height))\n",
    "plt.imshow(type_3)\n",
    "plt.show()\n",
    "\n",
    "type_3_x = np.expand_dims(type_3, axis=0)\n",
    "predictions = model.predict(type_3_x)\n",
    "index = np.argmax(predictions)\n",
    "\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_4 = load_img('MOUSE/10.png', target_size=(width, height))\n",
    "plt.imshow(type_4)\n",
    "plt.show()\n",
    "\n",
    "type_4_x = np.expand_dims(type_4, axis=0)\n",
    "predictions = model.predict(type_2_x)\n",
    "index = np.argmax(predictions)\n",
    "\n",
    "print(class_names[index])\n",
    "\n",
    "#Part 3 ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4 starts here\n",
    "\n",
    "#Live Predictions using camera\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "import time\n",
    "\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height= 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    _, frame = CAMERA.read()\n",
    "    \n",
    "    #Flip\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    #rescale the images output\n",
    "    aspect = frame.shape[1] / float(frame.shape[0])\n",
    "    res = int(aspect* camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "    \n",
    "    #Get roi\n",
    "    roi = frame[152:398, 302:648]\n",
    "\n",
    "    #Parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #adjust alignment\n",
    "    roi = cv2.resize(roi, (width, height))\n",
    "    roi_x = np.expand_dims(roi, axis=0)\n",
    "    \n",
    "    predictions = model.predict(roi_x)\n",
    "    type_1_x, type_2_x, type_3_x, type_4_x = predictions[0]\n",
    "    \n",
    "    #The green rectangle\n",
    "    cv2.rectangle(frame, (300, 150), (648, 398), (240, 100, 0), 2)\n",
    "    \n",
    "    #Predictions / Labels\n",
    "    \n",
    "    tipe_1_txt = '{} - {}%'.format(class_names[0], int(type_1_x*100))\n",
    "    cv2.putText(frame, tipe_1_txt, (70,210), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "    \n",
    "    tipe_2_txt = '{} - {}%'.format(class_names[1], int(type_2_x*100))\n",
    "    cv2.putText(frame, tipe_2_txt, (70,235), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "    \n",
    "    tipe_3_txt = '{} - {}%'.format(class_names[2], int(type_3_x*100))\n",
    "    cv2.putText(frame, tipe_3_txt, (70,255), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "    \n",
    "    tipe_4_txt = '{} - {}%'.format(class_names[3], int(type_4_x*100))\n",
    "    cv2.putText(frame, tipe_4_txt, (70,275), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "        \n",
    "    cv2.imshow(\"Real time object detection\", frame)\n",
    "    \n",
    "    #controls q = quit/ s = capturing\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key & 0xff == ord('q'):\n",
    "        break\n",
    "    \n",
    "    #preview\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camera\n",
    "CAMERA.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
