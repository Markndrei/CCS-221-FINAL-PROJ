{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetCreation ():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    %matplotlib inline\n",
    "    class_names = ['ID', 'NO LABEL', 'PHONE', 'MOUSE', 'CHERILYN']\n",
    "\n",
    "    #Creating Realtime Dataset\n",
    "\n",
    "    CAMERA = cv2.VideoCapture(0)\n",
    "    camera_height = 800\n",
    "\n",
    "    raw_frames_type_1 = []\n",
    "    raw_frames_type_2 = []\n",
    "    raw_frames_type_3 = []\n",
    "    raw_frames_type_4 = []\n",
    "    raw_frames_type_5 = []\n",
    "    while CAMERA.isOpened():\n",
    "        #Read a new camera frame\n",
    "        \n",
    "        ret, frame = CAMERA.read()\n",
    "        \n",
    "        #Flip\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        #Rescale the images output\n",
    "        \n",
    "        aspect = frame.shape[1] / float(frame.shape[0])\n",
    "        res = int(aspect * camera_height)\n",
    "        frame = cv2.resize(frame, (res, camera_height))\n",
    "        \n",
    "        #The green rectangle\n",
    "        cv2.rectangle(frame, (300, 150), (648, 398), (0, 255, 0), 2)\n",
    "        # cv2.rectangle(frame, (300, 75), (650, 425), (0,255,0), 2)\n",
    "        \n",
    "        #Show the frame\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        \n",
    "        #Controls q = quit/ s = capturing\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        if key & 0xff == ord('q'):\n",
    "            break\n",
    "        elif key & 0xFF == ord('1'):\n",
    "            #save the raw frames to frame\n",
    "            raw_frames_type_1.append(frame)\n",
    "        elif key & 0xFF == ord('2'):\n",
    "            #save the raw frames to frame\n",
    "            raw_frames_type_2.append(frame)\n",
    "        elif key & 0xFF == ord('3'):\n",
    "            #save the raw frames to frame\n",
    "            raw_frames_type_3.append(frame)\n",
    "        elif key & 0xFF == ord('4'):\n",
    "            #save the raw frames to frame\n",
    "            raw_frames_type_4.append(frame)\n",
    "        elif key & 0xFF == ord('5'):\n",
    "            #save the raw frames to frame\n",
    "            raw_frames_type_5.append(frame)\n",
    "            \n",
    "        #preview\n",
    "        # plt.imshow(frame)\n",
    "        # plt.show()\n",
    "\n",
    "    #Camera\n",
    "    CAMERA.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    save_width = 339\n",
    "    save_height = 600\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    retval = os.getcwd()\n",
    "    print(\"Current working directory %s\" % retval)\n",
    "\n",
    "    print('ID: ', len(raw_frames_type_1))\n",
    "    print('NO LABEL: ', len(raw_frames_type_2))\n",
    "    print('PHONE: ', len(raw_frames_type_3))\n",
    "    print('MOUSE: ', len(raw_frames_type_4))\n",
    "    print('CHERILYN: ', len(raw_frames_type_5))\n",
    "    \n",
    "    #Crop the images\n",
    "    #Edited to a loop\n",
    "\n",
    "    for class_idx, frames in enumerate([raw_frames_type_1, 
                                             raw_frames_type_2, 
                                             raw_frames_type_3,
                                             raw_frames_type_4,
                                             raw_frames_type_5]):\n",
    "        class_name = class_names[class_idx]\n",
    "\n",
    "        for i, frame in enumerate(frames):\n",
    "            # Get roi\n",
    "            roi = frame[152:398, 302:648]\n",
    "                \n",
    "            # Parse BRG to RGB\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "            # Resize to 224x224\n",
    "            roi = cv2.resize(roi, (save_width, save_height))\n",
    "                \n",
    "            # Save\n",
    "            cv2.imwrite('{}/{}.png'.format(class_name, i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    from glob import glob\n",
    "    from keras import preprocessing\n",
    "    from PIL import Image\n",
    "    width = 96\n",
    "    height = 96\n",
    "\n",
    "    images_type_1 = []\n",
    "    images_type_2 = []\n",
    "    images_type_3 = []\n",
    "    images_type_4 = []\n",
    "    images_type_5 = []\n",
    "\n",
    "    import keras.api._v2.keras as keras\n",
    "    from keras.utils import load_img, img_to_array, array_to_img \n",
    "\n",
    "    #Edited to a loop\n",
    "    images_list = [images_type_1, images_type_2, images_type_3, images_type_4, images_type_5]\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        images = images_list[class_idx]\n",
    "\n",
    "        for image_path in glob(f'{class_name}/*.*'):\n",
    "            img = Image.open(image_path).resize((width, height))\n",
    "            x = img_to_array(img)\n",
    "            images.append(x)\n",
    "    from glob import glob\n",
    "    from keras import preprocessing\n",
    "    from PIL import Image\n",
    "    width = 96\n",
    "    height = 96\n",
    "\n",
    "    images_type_1 = []\n",
    "    images_type_2 = []\n",
    "    images_type_3 = []\n",
    "    images_type_4 = []\n",
    "    images_type_5 = []\n",
    "\n",
    "    import keras.api._v2.keras as keras\n",
    "    from keras.utils import load_img, img_to_array, array_to_img \n",
    "\n",
    "    #Edited to a loop\n",
    "    images_list = [images_type_1, images_type_2, images_type_3, images_type_4, images_type_5]\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        images = images_list[class_idx]\n",
    "\n",
    "        for image_path in glob(f'{class_name}/*.*'):\n",
    "            img = Image.open(image_path).resize((width, height))\n",
    "            x = img_to_array(img)\n",
    "            images.append(x) \n",
    "\n",
    "    num_classes = 5\n",
    "    num_images_per_class = 5\n",
    "\n",
    "    for class_index in range(num_classes):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        images = globals()[f\"images_type_{class_index+1}\"][:num_images_per_class]\n",
    "        class_name = class_names[class_index]\n",
    "\n",
    "        for i, x in enumerate(images):\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            image = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "            plt.imshow(image)\n",
    "\n",
    "            plt.axis('off')\n",
    "            plt.title('{} image'.format(class_name))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # This is where part 1 ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessing (images_type_1, images_type_2, images_type_3, images_type_4, images_type_5, width, height, class_names):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    %matplotlib inline\n",
    "    from keras.utils import to_categorical\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "    from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    \n",
    "    #Prepare Image to tensor\n",
    "        \n",
    "    X_type_1 = np.array(images_type_1)\n",
    "    X_type_2 = np.array(images_type_2)\n",
    "    X_type_3 = np.array(images_type_3)\n",
    "    X_type_4 = np.array(images_type_4)\n",
    "    X_type_5 = np.array(images_type_5)\n",
    "\n",
    "    #Check the shape using .shape() check the images count\n",
    "\n",
    "    print(X_type_1.shape)\n",
    "    print(X_type_2.shape)\n",
    "    print(X_type_3.shape)\n",
    "    print(X_type_4.shape)\n",
    "    print(X_type_5.shape)\n",
    "    X = np.concatenate((X_type_1, X_type_2), axis = 0)\n",
    "    if len(X_type_3):\n",
    "        X = np.concatenate((X, X_type_3), axis = 0)\n",
    "        \n",
    "    if len(X_type_4):\n",
    "        X = np.concatenate((X, X_type_4), axis = 0)\n",
    "        \n",
    "    if len(X_type_5):\n",
    "        X = np.concatenate((X, X_type_5), axis = 0)\n",
    "        \n",
    "    #Scaling the data to 1 - 0\n",
    "\n",
    "    X = X / 255.0\n",
    "\n",
    "    X.shape\n",
    "\n",
    "    X = np.concatenate((X_type_1, X_type_2), axis = 0)\n",
    "\n",
    "    if len(X_type_3):\n",
    "        X = np.concatenate((X, X_type_3), axis = 0)\n",
    "        \n",
    "    if len(X_type_4):\n",
    "        X = np.concatenate((X, X_type_4), axis = 0)\n",
    "        \n",
    "    if len(X_type_5):\n",
    "        X = np.concatenate((X, X_type_5), axis = 0)\n",
    "        \n",
    "    #Scaling the data to 1 - 0\n",
    "\n",
    "    X = X / 255.0\n",
    "\n",
    "    X.shape\n",
    "\n",
    "    y_type_1 = [0 for item in enumerate(X_type_1)]\n",
    "    y_type_2 = [1 for item in enumerate(X_type_2)]\n",
    "    y_type_3 = [2 for item in enumerate(X_type_3)]\n",
    "    y_type_4 = [3 for item in enumerate(X_type_4)]\n",
    "    y_type_5 = [4 for item in enumerate(X_type_5)]\n",
    "\n",
    "    y = np.concatenate((y_type_1, y_type_2), axis = 0)\n",
    "\n",
    "    if len(y_type_3):\n",
    "        y = np.concatenate((y, y_type_3), axis = 0)\n",
    "        \n",
    "    if len(y_type_4):\n",
    "        y = np.concatenate((y, y_type_4), axis = 0)\n",
    "\n",
    "    if len(y_type_5):\n",
    "        y = np.concatenate((y, y_type_5), axis = 0)\n",
    "        \n",
    "    y = to_categorical(y, num_classes=len(class_names))\n",
    "\n",
    "    y.shape\n",
    "\n",
    "\n",
    "    #CNN Config\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "    from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    #Default Parameters\n",
    "\n",
    "    #Situational Values, you may not adjust these\n",
    "\n",
    "    conv_1 = 16\n",
    "    conv_1_drop = 0.2\n",
    "    conv_2 = 32\n",
    "    conv_2_drop = 0.2\n",
    "    dense_1_n = 1024\n",
    "    dense_1_drop = 0.2\n",
    "    dense_2_n = 512\n",
    "    dense_2_drop = 0.2\n",
    "\n",
    "    #values you can adjust\n",
    "    lr = 0.001\n",
    "    epochs = 10\n",
    "    batch_size = 30\n",
    "    color_channels = 3\n",
    "    \n",
    "    #Default Parameters\n",
    "\n",
    "    #Situational Values, you may not adjust these\n",
    "\n",
    "    conv_1 = 16\n",
    "    conv_1_drop = 0.2\n",
    "    conv_2 = 32\n",
    "    conv_2_drop = 0.2\n",
    "    dense_1_n = 1024\n",
    "    dense_1_drop = 0.2\n",
    "    dense_2_n = 512\n",
    "    dense_2_drop = 0.2\n",
    "\n",
    "    #values you can adjust\n",
    "    lr = 0.001\n",
    "    epochs = 10\n",
    "    batch_size = 30\n",
    "    color_channels = 3\n",
    "\n",
    "\n",
    "    def build_model(conv_1_drop = conv_1_drop, conv_2_drop = conv_2_drop,\n",
    "                    dense_1_n = dense_1_n, dense_1_drop = dense_1_drop,\n",
    "                    dense_2_n = dense_2_n, dense_2_drop = dense_2_drop,\n",
    "                    lr=lr):\n",
    "    \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Convolution2D(conv_1, (3,3),\n",
    "                                input_shape = (width, height, color_channels),\n",
    "                                activation = 'relu'))\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Dropout(conv_1_drop))\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        model.add(Convolution2D(conv_2, (3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(conv_1_drop))\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        model.add(Dense(dense_1_n, activation='relu'))\n",
    "        model.add(Dropout(dense_1_drop))\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        model.add(Dense(dense_2_n, activation='relu'))\n",
    "        model.add(Dropout(dense_2_drop))\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        model.add(Dense(len(class_names), activation='softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=Adam(clipvalue=0.5),\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    #model parameter\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.summary()\n",
    "    # Do not run yet\n",
    "\n",
    "    history = model.fit(X,y, validation_split=0.10, epochs=10, batch_size=30)\n",
    "\n",
    "    print(history)\n",
    "\n",
    "    #part 2 ends here\n",
    "\n",
    "\n",
    "    # Part 3 starts here\n",
    "\n",
    "    #Model evaluation\n",
    "\n",
    "    scores = model.evaluate(X, y, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss and accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    def plt_show(img):\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    id = 'ID/10.png'\n",
    "    nolabel = 'NO LABEL/10.png'\n",
    "    phone = 'PHONE/10.png'\n",
    "    mouse = 'MOUSE/10.png'\n",
    "    cherilyn = 'CHERILYN/10.png'\n",
    "\n",
    "    imgs = [id, nolabel, phone, mouse, cherilyn]\n",
    "\n",
    "    classes = None\n",
    "    predicted_classes = []\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        type_ = Image.open(imgs[i]).resize((width, height))\n",
    "        plt.imshow(type_)\n",
    "        plt.show()\n",
    "        \n",
    "        type_x      = np.expand_dims(np.array(type_), axis = 0)\n",
    "        prediction  = model.predict(type_x)\n",
    "        index       = np.argmax(prediction)\n",
    "        print(class_names[index])\n",
    "        classes     = class_names[index]\n",
    "        predicted_classes.append(class_names[index])\n",
    "        \n",
    "    cm = confusion_matrix(class_names, predicted_classes)\n",
    "    f = sns.heatmap(cm, xticklabels=class_names, yticklabels=predicted_classes, annot=True)\n",
    "    image_paths = ['ID/10.png', 'NO LABEL/10.png', 'PHONE/10.png', 'MOUSE/10.png', 'CHERILYN/10.png']\n",
    "\n",
    "    from keras.utils import load_img, img_to_array, array_to_img \n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(width, height))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        img_x = np.expand_dims(img, axis=0)\n",
    "        predictions = model.predict(img_x)\n",
    "        index = np.argmax(predictions)\n",
    "\n",
    "        print(class_names[index])\n",
    "\n",
    "    #Part 3 ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def livedetection (width, height, class_names, model):\n",
    "    #Part 4 starts here\n",
    "\n",
    "    #Live Predictions using camera\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "\n",
    "    from keras.applications import inception_v3\n",
    "    import time\n",
    "\n",
    "    CAMERA = cv2.VideoCapture(0)\n",
    "    camera_height= 500\n",
    "    while(True):\n",
    "        _, frame = CAMERA.read()\n",
    "        \n",
    "        #Flip\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        #rescale the images output\n",
    "        aspect = frame.shape[1] / float(frame.shape[0])\n",
    "        res = int(aspect* camera_height)\n",
    "        frame = cv2.resize(frame, (res, camera_height))\n",
    "        \n",
    "        #Get roi\n",
    "        roi = frame[100:360, 220:450]\n",
    "\n",
    "        #Parse BRG to RGB\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #adjust alignment\n",
    "        roi = cv2.resize(roi, (width, height))\n",
    "        roi_x = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        predictions = model.predict(roi_x)\n",
    "        type_1_x, type_2_x, type_3_x, type_4_x, type_5_x = predictions[0]\n",
    "        \n",
    "        #The blue rectangle\n",
    "        cv2.rectangle(frame, (220, 100), (450, 360), (240, 100, 0), 2)\n",
    "        \n",
    "        #Predictions / Labels\n",
    "        \n",
    "        tipe_1_txt = '{} - {}%'.format(class_names[0], int(type_1_x*100))\n",
    "        cv2.putText(frame, tipe_1_txt, (70,400), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "        \n",
    "        tipe_2_txt = '{} - {}%'.format(class_names[1], int(type_2_x*100))\n",
    "        cv2.putText(frame, tipe_2_txt, (70,420), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "        \n",
    "        tipe_3_txt = '{} - {}%'.format(class_names[2], int(type_3_x*100))\n",
    "        cv2.putText(frame, tipe_3_txt, (70,440), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "        \n",
    "        tipe_4_txt = '{} - {}%'.format(class_names[3], int(type_4_x*100))\n",
    "        cv2.putText(frame, tipe_4_txt, (70,460), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "        \n",
    "        tipe_5_txt = '{} - {}%'.format(class_names[4], int(type_5_x*100))\n",
    "        cv2.putText(frame, tipe_5_txt, (70,480), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(240,240,240),2)\n",
    "            \n",
    "        cv2.imshow(\"Real time object detection\", frame)\n",
    "        \n",
    "        #controls q = quit/ s = capturing\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        if key & 0xff == ord('q'):\n",
    "            break\n",
    "    \n",
    "    #preview\n",
    "    # plt.imshow(frame)\n",
    "    # plt.show()\n",
    "    #Camera\n",
    "    CAMERA.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main ():\n",
    "    datasetCreation ()\n",
    "    dataProcessing (images_type_1, images_type_2, images_type_3, images_type_4, images_type_5, width, height, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
